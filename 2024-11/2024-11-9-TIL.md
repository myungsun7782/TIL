# 2024-11-9-TIL

안녕하세요.

오늘은 컴퓨터 구조에서 캐시 메모리에 대해 알아보도록 할게요.

# 캐시 메모리

- CPU는 프로그램 실행 과정에서 빈번하게 메모리에 접근해야만 합니다.
- 하지만, CPU가 메모리에 접근하는 속도는 CPU가 레지스터에 접근하는 속도보다 느리기 때문에 CPU의 연산 속도가 아무리 빨라도 메모리에 접근하는 속도가 느리면 CPU의 빠른 연산 속도는 아무 효용이 없음. 
- 그래서 등장한 저장장치가 바로 캐시 메모리임.
- 캐시 메모리는 CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 탄생한 저장장치로, CPU와 메모리 사이에 위치한 SRAM 기반의 저장장치임.
- CPU가 매번 메모리에 왔다 갔다하는 시간이 오래걸리므로 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가져와 활용하자는 것임.
- 컴퓨터 내부에는 여러 종류의 캐시 메모리가 존재
- 이중 코어와 가장 가까운 캐시 메모리를 L1 캐시(Level 1 cache), 그 다음으로 가까운 캐시 메모리를 L2(Level 2 cache), 그 다음으로 가까운 캐시 메모리를 L3 캐시(Level 3 cache)라고 부름.
- 일반적으로 L1 캐시와 L2캐시는 코어 내부에, L3캐시는 코어 외부에 위치
- 캐시 메모리의 크기
  - L1 < L2 < L3
- 캐시 메모리의 속도
  - L3 < L2 < L1 의 순으로 빠름
- CPU가 메모리 내에 데이터가 필요하다고 판단하면 우선 L1 캐시 메모리에 해당 데이터가 있는지 알아보고, 없다면 L2, L3 캐시 메모리 순으로 데이터를 검색
- 멀티코어 프로세서의 경우 일반적으로 L1 캐시 메모리와 L2 캐시 메모리는 코어마다 고유한 캐시 메모리로 할당되고, L3 캐시는 여러 코어가 공유하는 형태로 구현됨
- 또한, 코어와 가장 가까운 L1 캐시 메모리는 명령어만을 저장하는 **L1l**캐시와 데이터만을 저장하는 L1캐시인 **L1D**캐시로 구분하기도 하며, 이러한 유형의 캐시 메모리를 **분리형 캐시(split cache)**라고 함.

### 캐시 히트와 캐시 미스

- 캐시 메모리는 메모리보다 용량이 작기 때문에 메모리에 있는 모든 내용을 캐시 메모리에 가져와 저장할 수는 없음.

- 메모리가 보조기억장치의 일부를 복사하여 저장하는 것처럼 캐시 메모리도 메모리의 일부를 복사하여 저장함

- 캐시 메모리에는 무엇을 저장할까?

  - 보조저장장치가 (전원이 꺼져도) 보관할 것을 저장하고, 메모리가 실행 중인 것을 저장한다면 캐시 메모리는 **CPU가 사용할 법한** 것을 저장

  - 이렇게 캐시 메모리가 예측하여 저장한 데이터가 CPU에 의해 실제로 사용되는 경우를 **캐시 히트(cache hit)**라고 하며, 반대로 자주 사용될 것으로 예측하여 캐시 메모리를 저장했지만 틀린 예측으로 인해 CPU가 메모리로부터 필요한 데이터를 직접 가져와야 하는 경우를 **캐시 미스(cache miss)**라고 함.
  - 만약, 캐시 미스가 발생한다면 캐시 메모리의 이점을 활용할 수 없게 되고, 캐시 히트에 비해 CPU의 성능이 떨어짐.
  - 참고로, 캐시가 히트되는 비율을 캐시 적중률(cache hit ratio)이라고 하며, 다음과 같이 계산함. 범용적으로 사용되는 컴퓨터의 캐시 적중률은 대략 85~95% 이상임.
    - 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

### 참조 지역성의 원리(locality of reference, principle of locality)

- 캐시 메모리의 이점을 제대로 활용하려면 CPU가 사용할 법한 데이터를 제대로 예측해서 캐시 적중률을 높여야 함.
- 그렇다면 CPU가 사용할 법한 데이터는 어떻게 예측할 수 있을까?
- 캐시 메모리는 참조 지역성의 원리라는 특정한 원칙에 따라 메모리로부터 가져올 데이터를 결정함.
- 참조 지역성의 원리란, CPU가 메모리에 접근할 때 보이는 다음과 같은 주된 경향을 의미
  - 시간 지역성: CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있음
  - 공간 지역성: CPU는 접근한 메모리 공간의 근처에 접근하려는 경향이 있음
- 시간 지역성을 가장 잘 보이는 사례는 프로그래밍 언어의 **변수**임. 일반적으로 변수에 저장된 값은 한 번만 사용되지 않고, 프로그램이 실행되는 동안 여러 번 사용됨. 즉, CPU는 최근에 접근했던 (변수가 저장된) 메모리 공간에 여러번 다시 접근할 수 있음. 이렇게 최근에 접근했던 메모리 공간에 다시 접근하려는 경향을 **시간 지역성**이라고 함.
- 접근한 메모리 공간의 근처에 접근하려는 경향인 공간 지역성을 단적으로 보여주는 사례는 **배열**임.

### 캐시 메모리의 쓰기 정책과 일관성

- CPU가 캐시 메모리에 데이터를 쓸 때는 캐시 메모리에 새롭게 쓰여진 데이터와 메모리 상의 데이터가 일관성을 유지해야 함
- 예를 들어, 현재 메모리에 1000번지에 200이라는 값이 저장되어 있고, 이 값이 캐시 메모리에도 저장되어 있다고 가정해 보자. CPU가 이 값에 접근하고자 할 때는 당연히 앞서 배웠던 것처럼 캐시 메모리를 통해 값을 얻어낼 것임.
- 이 때, 만약 CPU가 이 값을 200에서 300으로 바꾸고 싶다면 어떻게 해야할까? 곧장 메모리 1000번지에 달려가 값을 300으로 바꾸는 것은 좋은 생각이 아님. 현재 CPU는 1000번지 값을 얻기 위해 캐시 메모리를 참조하고 있기 때문에 메모리 1000번지 값을 무작정 300으로 바꾼다면 다음과 같은 명령어를 수행할 때 예상치 못한 결과가 나타날 수 있기 때문
  - 명령어1: 1000번지 값을 300으로 바꾸기 // 메모리 1000번지의 값: 300, 캐시 메모리 내의 값: 200
  - 명령어2: 1000번지 값 출력하기 // 캐시 메모리를 읽어 들일 경우 여전히 200을 출력
- 위와 같은 문제를 방지하기 위한 방법에는 크게 2가지가 있음
  - 하나는 캐시 메모리와 메모리에 동시에 쓰는 방법이 있을 수 있음. 이를 **즉시 쓰기(write-through)**라고 함. 즉시 쓰기는 메모리를 항상 최신 상태로 유지하여 캐시 메모리와 메모리 간의 일관성이 꺠지는 상황을 방지할 수 있지만, 데이터를 쓸 때마다 메모리를 참조해야 하므로 버스의 사용 시간과 쓰기 시간이 늘어난다는 단점이 있음
    - 메모리 접근을 최소화하기 위해 캐시 메모리를 만들었는데, 데이터를 쓸 때마다 메모리와 캐시 메모리에 동시에 접근해야 한다면 캐시 메모리를 둔 효율이 떨어질 것임.
  - 두번째는 캐시 메모리에만 값을 써두었다가 추후 수정된 데이터를 한 번에 메모리에 반영하는 방법이 있음. 이를 **지연 쓰기(write-back)**라고 함. 메모리 접근 횟수를 줄일 수 있어 즉시 쓰기 방식에 비해 속도는 더 빠르지만, 메모리와 캐시 메모리 간의 일관성이 깨질 수 있다는 위험을 감수해야 함.
- 캐시 메모리와 메모리 간의 불일치만 해결해야 하는 것이 아님. 때로는 다른 코어가 사용하는 캐시 메모리와의 불일치도 발생할 수 있음. 자칫 각기 다른 코어가 서로 다른 데이터를 대상으로 작업할 수 있기 때문
- 중요한 것은, 캐시 메모리를 사용한다는 것, 나아가 캐싱을 한다는 것은 데이터 접근에 있어 어느 정도의 빠른 성능은 보장할 수 있지만, 그와 동시에 데이터의 일관성을 유지하기 위한 책임이 따르는 방식이라는 것임.

<br/>

<br/>

오늘 공부한 내용은 여기까지 입니다.

읽어주셔서 감사합니다.

 